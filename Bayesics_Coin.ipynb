{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "762db443-19b4-4d7d-9c4e-5fa752bc9f73",
   "metadata": {},
   "source": [
    "# Internship Finn Sherry @ Sioux Mathware\n",
    "\n",
    "---\n",
    "\n",
    "# Bayesian grey-box system identification for thermal effects: Biased Coins and MAB\n",
    "In this notebook, we will become familiar with Bayesian inference. First, we will try to identify the bias of a coin. Then, we will tackle the Multi-Armed Bandit (MAB) problem.\n",
    "\n",
    "Last update: 19-07-2022\n",
    "\n",
    "$\\renewcommand{\\vec}[1]{\\boldsymbol{\\mathrm{#1}}}$\n",
    "$\\newcommand{\\covec}[1]{\\hat{\\vec{#1}}}$\n",
    "$\\newcommand{\\mat}[1]{\\boldsymbol{\\mathrm{#1}}}$\n",
    "$\\newcommand{\\inv}[1]{#1^{-1}}$\n",
    "$\\newcommand{\\given}{\\, \\vert \\,}$\n",
    "$\\newcommand{\\haslaw}{\\sim}$\n",
    "$\\newcommand{\\problaw}[1]{p(#1)}$\n",
    "$\\newcommand{\\Expectation}{\\mathbb{E}}$\n",
    "$\\newcommand{\\Variance}{\\mathbb{V}}$\n",
    "$\\newcommand{\\Geometric}{\\textrm{Geom}}$\n",
    "$\\newcommand{\\NegBin}{\\textrm{NB}}$\n",
    "$\\newcommand{\\Poisson}{\\textrm{Pois}}$\n",
    "$\\newcommand{\\Bernoulli}{\\textrm{Bern}}$\n",
    "$\\newcommand{\\Uniform}{\\textrm{Uni}}$\n",
    "$\\newcommand{\\NormDist}{\\mathcal{N}}$\n",
    "$\\newcommand{\\GammaDist}{\\textrm{Gamma}}$\n",
    "$\\newcommand{\\ExpDist}{\\textrm{Exp}}$\n",
    "$\\newcommand{\\Uniform}{\\textrm{Uniform}}$\n",
    "$\\newcommand{\\Binomial}{\\textrm{Binom}}$\n",
    "$\\newcommand{\\BetaDist}{\\textrm{Beta}}$\n",
    "$\\newcommand{\\BetaFunc}{\\textrm{B}}$\n",
    "$\\newcommand{\\setify}[1]{\\mathbb{#1}}$\n",
    "$\\newcommand{\\NatSet}{\\setify{N}}$\n",
    "$\\newcommand{\\IntSet}{\\setify{Z}}$\n",
    "$\\newcommand{\\RealSet}{\\setify{R}}$\n",
    "$\\newcommand{\\CompSet}{\\setify{C}}$\n",
    "$\\newcommand{\\QuatSet}{\\setify{H}}$\n",
    "$\\newcommand{\\FieldSet}{\\setify{K}}$\n",
    "$\\newcommand{\\define}{:=}$\n",
    "$\\newcommand{\\enifed}{=:}$\n",
    "$\\newcommand{\\loss}{\\ell}$\n",
    "$\\newcommand{\\risk}{\\textrm{R}}$\n",
    "$\\newcommand{\\MSE}{\\textrm{MSE}}$\n",
    "$\\newcommand{\\norm}[1]{\\lVert #2 \\rVert}$\n",
    "$\\newcommand{\\InnerProduct}[2]{\\left( #1 , #2 \\right)}$\n",
    "$\\newcommand{\\kilogram}{\\textrm{kg}}$\n",
    "$\\newcommand{\\metre}{\\textrm{m}}$\n",
    "$\\newcommand{\\watt}{\\textrm{W}}$\n",
    "$\\newcommand{\\joule}{\\textrm{J}}$\n",
    "$\\newcommand{\\kelvin}{\\textrm{K}}$\n",
    "$\\newcommand{\\second}{\\textrm{s}}$\n",
    "$\\newcommand{\\centi}{\\textrm{c}}$\n",
    "$\\newcommand{\\bigO}{\\mathcal{O}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243df9ab-8870-443a-9b9a-d232ba854c90",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Identifying Bias of a Coin\n",
    "Suppose we have a coin, which flips ‘heads’ (or 1) with probability $p \\in [0, 1]$ and ‘tails’ (or 0) with probability $1 − p$. We would like to find out the value of $p$, or equivalently the bias of the coin $p - \\frac{1}{2}$. We have some limited knowledge on $p$, namely $p \\in [0, 1]$. Moreover, we know that the value of each observation $y \\sim \\Bernoulli(p)$. Hence, for the observation model $y$ given $p$ we have the law\n",
    "$$\\problaw{y \\given p} = p^y (1 − p)^{1 − y} =\n",
    "\\begin{cases}\n",
    "p, y = 1, \\\\\n",
    "1 − p, y = 0.\n",
    "\\end{cases}$$\n",
    "A sensible choice for a prior on $p$ would then be $\\BetaDist(1, 1)$: \n",
    "- The support of the Beta distribution is $[0, 1]$;\n",
    "- The Beta distribution turns out to be the conjugate prior of the Bernoulli distribution, which means that it is relatively straightforward to get a closed form expression for the posterior.\n",
    "\n",
    "Suppose we have as prior $p \\sim \\BetaDist(\\alpha, \\beta)$ for some $\\alpha, \\beta \\geq 0$. It is then possible to derive that \n",
    "$$p \\mid y \\sim \\BetaDist(\\alpha + y, \\beta + 1 - y).$$\n",
    "<details>\n",
    "<summary><b>Proof</b></summary>\n",
    "  \n",
    "Suppose $p \\haslaw \\BetaDist(\\alpha, \\beta)$ for some known $\\alpha, \\beta > 0$ and $y \\haslaw \\Bernoulli(p)$. Then, by the definition of the [Beta distribution](https://en.wikipedia.org/wiki/Beta_distribution), we know that\n",
    "$$\\problaw{p} = \\frac{p^{\\alpha - 1} (1 - p)^{\\beta - 1}}{\\BetaFunc(\\alpha, \\beta)},$$\n",
    "where \n",
    "$$\\BetaFunc(\\alpha, \\beta) = \\int_0^1 x^{\\alpha - 1} (1 - x)^{\\beta - 1} dx$$\n",
    "is the Beta function. According to the Law of Total Probability, we may find that the evidence is given by\n",
    "$$\\problaw{y} = \\int_0^1 \\problaw{y \\given p} \\problaw{p} dp.$$\n",
    "We can therefore apply Bayes' Rule to find that\n",
    "$$\\begin{align}\n",
    "\\problaw{p \\given y} & = \\frac{\\problaw{y \\given p} \\problaw{p}}{\\problaw{y}} = \\frac{\\problaw{y \\given p} \\problaw{p}}{\\int_0^1 \\problaw{y \\given p} \\problaw{p} dp} = \\dfrac{p^y (1 - p)^{1 - y} \\frac{p^{\\alpha - 1} (1 - p)^{\\beta - 1}}{\\BetaFunc(\\alpha, \\beta)}}{\\int_0^1 p^{y} (1 - p)^{1 - y} \\frac{q^{\\alpha - 1} (1 - p)^{\\beta - 1}}{\\BetaFunc(\\alpha, \\beta)} dp} \n",
    "\\\\\n",
    "& = \\dfrac{p^{\\alpha + y - 1} (1 - p)^{\\beta + 1 - y - 1}}{\\int_0^1 p^{\\alpha + y - 1} (1 - p)^{\\beta + 1 - y - 1} dp} = \\frac{p^{\\alpha + y - 1} (1 - p)^{\\beta + 1 - y - 1}}{\\BetaFunc(\\alpha + y, \\beta + 1 - y)}.\n",
    "\\end{align}$$\n",
    "We now recognise the probability density function (pdf) of a random variable distributed as $\\BetaDist(\\alpha + y, \\beta + 1 - y)$, so that indeed $p \\given y \\haslaw \\BetaDist(\\alpha + y, \\beta + 1 - y)$, as required.\n",
    "</details>\n",
    "This is all we need to come up with an iterative algorithm which allows us to estimate the parameter $p$ online as we make observations. We start with some initial prior $\\problaw{p}$, and make observations $(y_1, \\dots, y_{100}) \\enifed y_{1:100}$. Then, we compute the posterior $\\problaw{p \\given y_1}$ using Bayes' Rule. Suppose we have determined the posterior $\\problaw{p \\given y_{1:k}}$. Then, we treat it as a prior for $p$, and update using $y_{k + 1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1652400c-0cc6-44f5-afd6-3d4f3a0f7b9a",
   "metadata": {},
   "source": [
    "We will now apply this in the following example. For this, we will make use of the package [Distributions.jl](https://github.com/JuliaStats/Distributions.jl), which includes most common distributions, and makes it easy to plot densities. For the calculations themselves it is actually overkill to define distributions, since we can simply update the two parameters of the Beta distribution prior directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8a7842-2695-4edc-baf6-e4a9ac17aa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributions, Random, StatsPlots, StatsBase, LazySets, LaTeXStrings\n",
    "Random.seed!(987654321) # Seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dff5a7-d3b7-4757-831e-34993b72f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.5 # True probability of heads\n",
    "N = 100 # Number of observations\n",
    "prior_init = [1, 1] # Parameters of the initial prior\n",
    "obs = rand(Bernoulli(p), N); # Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3530d3b7-d759-4144-acf1-233b75e44d6e",
   "metadata": {},
   "source": [
    "The update rule for the prior can be written in a single line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392afb0d-0e96-4e13-af84-963e1b35e686",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_recursive(prior, y::Bool) = prior .+ [y, 1 - y]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168bf2a9-9f70-409c-b68c-81b485318d65",
   "metadata": {},
   "source": [
    "Finally, we perform the inference recursively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9733730-2d82-4461-8a77-b19647e2b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_gif_recursive(prior, data::Vector{Bool}, p_true)\n",
    "    post = prior\n",
    "    @gif for (n, y) ∈ enumerate(data)\n",
    "        post = post_recursive(post, y)\n",
    "        plot(Beta(post[1], post[2]); size = (800, 800), fillalpha = 0.3, fillrange = 0, title = \"Posterior after $n observations\", xlabel = \"p\", ylabel = \"density\", xlim = (0, 1), legend = nothing)\n",
    "        vline!([p_true])\n",
    "    end \n",
    "end\n",
    "make_gif_recursive(prior_init, obs, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79948a06-df1a-432b-805a-f7f52efeb046",
   "metadata": {},
   "source": [
    "As the number of observations increases, the posterior becomes narrower, and tends to centre around the true value $p = \\frac{1}{2}$. The peak of the posterior distribution is the Maximum A Posteriori (MAP) estimate. It is the value of the parameter that best explains the data, while incorporating the information from the prior. This recursive approach to Bayesian inference is also called _filtering_, and we will go into more detail about it in [this notebook](Bayesics_Filtering.ipynb).\n",
    "\n",
    "In this case it is pretty easy to directly get a _batch_ estimate, i.e. to update the prior with an entire \"batch\" of data at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e566363-3611-4bae-9179-2f3f0a046cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_batch(prior, data::Vector{Bool}) = prior .+ [sum(data), length(data) - sum(data)]\n",
    "\n",
    "post_final = post_batch(prior_init, obs)\n",
    "plot(Beta(post_final[1], post_final[2]); size = (800, 800), fillalpha = 0.3, fillrange = 0, title = \"Posterior after $(N) observations\", xlabel = \"p\", ylabel = \"density\", xlim = (0, 1), legend = nothing)\n",
    "vline!([p])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be21593-73b4-4f14-a19b-5a720d9ed92f",
   "metadata": {},
   "source": [
    "The posterior distribution $p(p \\mid y_{1:100})$ allows us to (centred) construct credible. For instance, to construct a 95 % credible interval, we would take the 2.5 % and the 97.5 % quantile of the posterior distribution. In this example, that would give:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b877b59c-8c87-41dc-a96b-9937f10c636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_dist = Beta(post_final[1], post_final[2])\n",
    "left_quant = quantile(post_dist, 0.025)\n",
    "right_quant = quantile(post_dist, 0.975)\n",
    "left_quant, right_quant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d78de9-0fbb-42dd-a368-6cd27cecf61d",
   "metadata": {},
   "source": [
    "Hence, the 95 % credible interval we have found is $[0.356, 0.548]$, which indeed contains the true value of $p$. If we use a more biased coin, we would expect to get a narrower posterior and consequently a tighter credible interval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461a1887-cf79-47a3-a0c1-d72b30cda315",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.9 # True probability of heads, very biased\n",
    "prior_init = [1, 1] # Parameters of the initial prior\n",
    "obs = rand(Bernoulli(p), N); # Observations\n",
    "make_gif_recursive(prior_init, obs, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e0d084-d47f-4efe-93b5-367d58785a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_final = post_batch(prior_init, obs)\n",
    "post_dist = Beta(post_final[1], post_final[2])\n",
    "left_quant = quantile(post_dist, 0.025)\n",
    "right_quant = quantile(post_dist, 0.975)\n",
    "left_quant, right_quant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea5095d-5404-458c-ba96-fb5d0428df68",
   "metadata": {},
   "source": [
    "Now the 95 % credible interval we have found is $[0.838, 0.951]$: it is about half as wide as the previous credible interval, but it still contains the true value of $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d904aac8-9880-4469-8dda-59daa067c218",
   "metadata": {},
   "source": [
    "## Multi-Armed Bandit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c9f9c8-e129-4aee-984a-79b4cc29128f",
   "metadata": {},
   "source": [
    "We could also use this filtering approach to tackle the multi-armed bandit problem. This problem is modelled on a row of $N$ slot machines, each with fixed but unknown probability of cashing out. If we consider only binary pay outs, then this system is equivalent to $N$ coins with fixed but unknown bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c45b138-2572-461f-979c-fbc170c3ccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_arms = 6\n",
    "ps = rand(N_arms)\n",
    "N = 100\n",
    "priors_init = [[1, 1] for _ in 1:N_arms];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433e8457-6b9d-487c-8523-87f8fddcb3f4",
   "metadata": {},
   "source": [
    "The goal is to maximise the gain. We have to trade off exploration, in which we flip coins that we have not tried as often yet to increase our knowledge of their success probabilities, and exploitation, in which we flip coins that we currently believe have high success probabilities. Our knowledge of the success probabilities will be encoded in the posteriors, which we can determine recursively using posterior recursive. Now we must come up with a good strategy that balances exploration and exploitation. To incorporate the exploitation aspect, we could prioritise arms whose posteriors have a high mean. To incorporate the exploration aspect, we could make use of the width of the posteriors. For instance, the 95 % credible interval will be wide if we know little about the success probability of a given coin. To combine these, we could choose arms based on the value of the top of their 95 % credible interval. This strategy is essentially the [Uniform Confidence Bound (UCB) strategy](https://en.wikipedia.org/wiki/Multi-armed_bandit). In Julia, we can select the corresponding index using the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab56eb4-3cf1-4c67-a1ab-926c0a337095",
   "metadata": {},
   "outputs": [],
   "source": [
    "function choose_arm(posts)\n",
    "    dists = [Beta(post[1], post[2]) for post in posts]\n",
    "    cred_int_tops = [quantile(dist, 0.975) for dist in dists]\n",
    "    return argmax(cred_int_tops)[1]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e878947-d02f-45f7-ac47-d3137a0a6e7d",
   "metadata": {},
   "source": [
    "Notably, if there are multiple arms which achieve the maximum, `argmax` will choose one at random. Then, we can simulate this strategy as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bab001a-4e1b-485f-99b4-ffe8f2a01986",
   "metadata": {},
   "outputs": [],
   "source": [
    "function plot_posts(posts, true_ps, n)\n",
    "    c_arms = size(posts)[1]\n",
    "    dists = [Beta(post[1], post[2]) for post in posts]\n",
    "    means = mean.(dists)\n",
    "    ptops = quantile.(dists, 0.975)\n",
    "    pbots = quantile.(dists, 0.025)\n",
    "    dist_plot = scatter(1:c_arms, means, title = \"Posteriors after $n Observations\", xlabel = \"Arm\", ylabel = \"p\", label = \"Posterior mean\", xlim = (0.5, c_arms + 0.5), ylim = (0, 1))\n",
    "    scatter!(dist_plot, 1:c_arms, true_ps, label = \"True p\")\n",
    "    for arm ∈ 1:c_arms\n",
    "        ls = LineSegment([arm, pbots[arm]], [arm, ptops[arm]])\n",
    "        plot!(dist_plot, ls, linecolor = \"black\", ylim = (0, 1))\n",
    "    end\n",
    "end\n",
    "\n",
    "function explore_and_exploit_plot(priors, true_ps, sample_size)\n",
    "    posts = copy(priors)\n",
    "    @gif for n ∈ 1:sample_size\n",
    "        arm = choose_arm(posts)\n",
    "        success = rand(Bernoulli(true_ps[arm]))\n",
    "        posts[arm] = post_recursive(posts[arm], success)\n",
    "        plot_posts(posts, true_ps, n)\n",
    "    end \n",
    "end\n",
    "explore_and_exploit_plot(priors_init, ps, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3e1153-832c-4dfe-b546-8e3261040ba8",
   "metadata": {},
   "source": [
    "In this example, we see that the strategy quickly finds the best arm, and then exploits it. To quantify the strategy, we compare it to an approach where the arm is chosen at random. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61342558-5b24-4ee5-bfe6-838affe284bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "function explore_and_exploit(priors, true_ps, sample_size)\n",
    "    posts = copy(priors)\n",
    "    successes = 0\n",
    "    for _ ∈ 1:sample_size\n",
    "        arm = choose_arm(posts)\n",
    "        success = rand(Bernoulli(true_ps[arm]))\n",
    "        posts[arm] = post_recursive(posts[arm], success)\n",
    "        successes += success\n",
    "    end \n",
    "    return successes / sample_size\n",
    "end\n",
    "\n",
    "function random_selection(true_ps, sample_size)\n",
    "    successes = 0\n",
    "    for _ in 1:sample_size\n",
    "        p_cur = rand(true_ps)\n",
    "        successes += rand(Bernoulli(p_cur))\n",
    "    end\n",
    "    return successes / sample_size\n",
    "end\n",
    "\n",
    "function plot_dists_strategies_multi(priors, true_ps, sample_size, number_tests)\n",
    "    dist_random = Vector{Float64}(undef, number_tests)\n",
    "    dist_explore_exploit = Vector{Float64}(undef, number_tests)\n",
    "    for n ∈ 1:number_tests\n",
    "        dist_random[n] = random_selection(true_ps, sample_size)\n",
    "        dist_explore_exploit[n] = explore_and_exploit(priors, true_ps, sample_size)\n",
    "    end\n",
    "    p_dists = histogram(dist_random, title = \"Empirical Distributions of Average Gain after $(sample_size) Steps\", normalize = :pdf, xlim = (0, 1), ylim = (0, 10), xlabel = \"Average Gain\", ylabel = \"Density\", label = \"Random Selection\", size = (800, 800))\n",
    "    histogram!(p_dists, dist_explore_exploit, normalize = :pdf, label = \"Bayesian Selection\")\n",
    "    vline!(p_dists, [true_ps], linecolor = \"black\", label = \"p\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be1b43b-afcf-4c7e-a0c3-7ae6bcdba1d3",
   "metadata": {},
   "source": [
    "For this comparison, we will approximate the distribution of the average gain, i.e. the number of successes over the total number of arms pulled, after 100 goes. This approximation is done by running such a test 5000 independent times. We would expect that choosing an arm at random would give us an average gain that is roughly the average of the success probabilities, while hopefully the Bayesian approach will give a higher average gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e185d08-a6a9-4b22-b918-28e02c75f697",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_tests = 5000\n",
    "plot_dists_strategies_multi(priors_init, ps, N, N_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d45d31-b5a6-4561-96e6-abe54a89b437",
   "metadata": {},
   "source": [
    "The mean of the success probabilities is $p = 0.495$, and the distribution of the average gain of the random method is roughly centred around $\\bar{p} = 0.5$. On the other hand, our Bayesian approach performs much better, with an average gain that is typically almost as high as the highest success probability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
